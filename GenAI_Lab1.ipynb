{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyPi9c9mGIKzJw3r/gTGhV8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matrix-69/GenAI/blob/main/GenAI_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from collections import Counter\n",
        "\n",
        "# Download required NLTK data (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Added to resolve new LookupError\n",
        "\n",
        "# Load spaCy model (run once in terminal if not installed)\n",
        "# python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"Porsche, founded by Ferdinand Porsche in 1931 and headquartered in Stuttgart, is a renowned German manufacturer of high-performance luxury sports cars, SUVs, and sedans.\"\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Tokenization\n",
        "# -----------------------------\n",
        "tokens = word_tokenize(text)\n",
        "print(\"\\nTokens:\")\n",
        "print(tokens)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Stop Word Removal\n",
        "# -----------------------------\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
        "\n",
        "print(\"\\nAfter Stop Word Removal:\")\n",
        "print(filtered_tokens)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Stemming\n",
        "# -----------------------------\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
        "\n",
        "print(\"\\nStemming:\")\n",
        "print(stemmed_words)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Lemmatization\n",
        "# -----------------------------\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "print(\"\\nLemmatization:\")\n",
        "print(lemmatized_words)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. POS Tagging\n",
        "# -----------------------------\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(\"\\nPOS Tagging:\")\n",
        "print(pos_tags)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Named Entity Recognition (NER)\n",
        "# -----------------------------\n",
        "doc = nlp(text)\n",
        "print(\"\\nNamed Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \"->\", ent.label_)\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Word Frequency Analysis\n",
        "# -----------------------------\n",
        "word_freq = Counter(filtered_tokens)\n",
        "\n",
        "print(\"\\nWord Frequency:\")\n",
        "for word, freq in word_freq.items():\n",
        "    print(word, \":\", freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzbh_Or3jdkX",
        "outputId": "e3acc277-838f-400c-cc48-0ce37845cf2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens:\n",
            "['Porsche', ',', 'founded', 'by', 'Ferdinand', 'Porsche', 'in', '1931', 'and', 'headquartered', 'in', 'Stuttgart', ',', 'is', 'a', 'renowned', 'German', 'manufacturer', 'of', 'high-performance', 'luxury', 'sports', 'cars', ',', 'SUVs', ',', 'and', 'sedans', '.']\n",
            "\n",
            "After Stop Word Removal:\n",
            "['Porsche', 'founded', 'Ferdinand', 'Porsche', '1931', 'headquartered', 'Stuttgart', 'renowned', 'German', 'manufacturer', 'luxury', 'sports', 'cars', 'SUVs', 'sedans']\n",
            "\n",
            "Stemming:\n",
            "['porsch', 'found', 'ferdinand', 'porsch', '1931', 'headquart', 'stuttgart', 'renown', 'german', 'manufactur', 'luxuri', 'sport', 'car', 'suv', 'sedan']\n",
            "\n",
            "Lemmatization:\n",
            "['Porsche', 'founded', 'Ferdinand', 'Porsche', '1931', 'headquartered', 'Stuttgart', 'renowned', 'German', 'manufacturer', 'luxury', 'sport', 'car', 'SUVs', 'sedan']\n",
            "\n",
            "POS Tagging:\n",
            "[('Porsche', 'NNP'), (',', ','), ('founded', 'VBN'), ('by', 'IN'), ('Ferdinand', 'NNP'), ('Porsche', 'NNP'), ('in', 'IN'), ('1931', 'CD'), ('and', 'CC'), ('headquartered', 'VBD'), ('in', 'IN'), ('Stuttgart', 'NNP'), (',', ','), ('is', 'VBZ'), ('a', 'DT'), ('renowned', 'JJ'), ('German', 'JJ'), ('manufacturer', 'NN'), ('of', 'IN'), ('high-performance', 'JJ'), ('luxury', 'NN'), ('sports', 'NNS'), ('cars', 'NNS'), (',', ','), ('SUVs', 'NNP'), (',', ','), ('and', 'CC'), ('sedans', 'NNS'), ('.', '.')]\n",
            "\n",
            "Named Entities:\n",
            "Porsche -> ORG\n",
            "Ferdinand Porsche -> ORG\n",
            "1931 -> DATE\n",
            "Stuttgart -> GPE\n",
            "German -> NORP\n",
            "\n",
            "Word Frequency:\n",
            "Porsche : 2\n",
            "founded : 1\n",
            "Ferdinand : 1\n",
            "1931 : 1\n",
            "headquartered : 1\n",
            "Stuttgart : 1\n",
            "renowned : 1\n",
            "German : 1\n",
            "manufacturer : 1\n",
            "luxury : 1\n",
            "sports : 1\n",
            "cars : 1\n",
            "SUVs : 1\n",
            "sedans : 1\n"
          ]
        }
      ]
    }
  ]
}